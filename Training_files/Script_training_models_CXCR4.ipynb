{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "from statistics import mean\n",
    "from rdkit.Chem import Descriptors, rdMolDescriptors, PandasTools, AllChem\n",
    "from scipy.stats import loguniform, randint, uniform\n",
    "from boruta import BorutaPy\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score, confusion_matrix,matthews_corrcoef\n",
    "from sklearn.metrics import make_scorer, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, f1_score, roc_curve, precision_score, cohen_kappa_score, accuracy_score, r2_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading of calculated discriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Ids</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Smiles</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>SPS</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>pk1</td>\n",
       "      <td>1</td>\n",
       "      <td>CN1CCN(CC1)c1cc(CN2CCC[C@H]2c2ncccc2C)nc(C)n1</td>\n",
       "      <td>4.747386</td>\n",
       "      <td>4.747386</td>\n",
       "      <td>0.396813</td>\n",
       "      <td>0.396813</td>\n",
       "      <td>0.828903</td>\n",
       "      <td>21.740741</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pk2</td>\n",
       "      <td>1</td>\n",
       "      <td>CN1CCCN(CC1)c1cc(CN2CCC[C@H]2c2ncccc2C)nc(C)n1</td>\n",
       "      <td>4.770823</td>\n",
       "      <td>4.770823</td>\n",
       "      <td>0.395146</td>\n",
       "      <td>0.395146</td>\n",
       "      <td>0.812758</td>\n",
       "      <td>21.821429</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>pk3</td>\n",
       "      <td>1</td>\n",
       "      <td>CN(Cc1cc(ncn1)N1CCN(C)CC1)[C@H]1CCCc2cccnc12</td>\n",
       "      <td>4.674182</td>\n",
       "      <td>4.674182</td>\n",
       "      <td>0.376853</td>\n",
       "      <td>0.376853</td>\n",
       "      <td>0.840163</td>\n",
       "      <td>21.038462</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>pk4</td>\n",
       "      <td>1</td>\n",
       "      <td>C(N1CCNCCc2cccc(CCNCC1)n2)c1ccc(CN2CCNCCc3cccc...</td>\n",
       "      <td>4.807727</td>\n",
       "      <td>4.807727</td>\n",
       "      <td>0.975697</td>\n",
       "      <td>0.975697</td>\n",
       "      <td>0.379775</td>\n",
       "      <td>19.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>pk5</td>\n",
       "      <td>1</td>\n",
       "      <td>CC(C)(C)OC(=O)Cn1c2ccccc2c2ccnc(CN(CCCCN)[C@H]...</td>\n",
       "      <td>13.011991</td>\n",
       "      <td>13.011991</td>\n",
       "      <td>0.139849</td>\n",
       "      <td>-0.543564</td>\n",
       "      <td>0.233446</td>\n",
       "      <td>15.763158</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Ids  Activity  \\\n",
       "0           0  pk1         1   \n",
       "1           1  pk2         1   \n",
       "2           2  pk3         1   \n",
       "3           3  pk4         1   \n",
       "4           4  pk5         1   \n",
       "\n",
       "                                              Smiles  MaxAbsEStateIndex  \\\n",
       "0      CN1CCN(CC1)c1cc(CN2CCC[C@H]2c2ncccc2C)nc(C)n1           4.747386   \n",
       "1     CN1CCCN(CC1)c1cc(CN2CCC[C@H]2c2ncccc2C)nc(C)n1           4.770823   \n",
       "2       CN(Cc1cc(ncn1)N1CCN(C)CC1)[C@H]1CCCc2cccnc12           4.674182   \n",
       "3  C(N1CCNCCc2cccc(CCNCC1)n2)c1ccc(CN2CCNCCc3cccc...           4.807727   \n",
       "4  CC(C)(C)OC(=O)Cn1c2ccccc2c2ccnc(CN(CCCCN)[C@H]...          13.011991   \n",
       "\n",
       "   MaxEStateIndex  MinAbsEStateIndex  MinEStateIndex       qed        SPS  \\\n",
       "0        4.747386           0.396813        0.396813  0.828903  21.740741   \n",
       "1        4.770823           0.395146        0.395146  0.812758  21.821429   \n",
       "2        4.674182           0.376853        0.376853  0.840163  21.038462   \n",
       "3        4.807727           0.975697        0.975697  0.379775  19.428571   \n",
       "4       13.011991           0.139849       -0.543564  0.233446  15.763158   \n",
       "\n",
       "   ...  fr_sulfide  fr_sulfonamd  fr_sulfone  fr_term_acetylene  fr_tetrazole  \\\n",
       "0  ...           0             0           0                  0             0   \n",
       "1  ...           0             0           0                  0             0   \n",
       "2  ...           0             0           0                  0             0   \n",
       "3  ...           0             0           0                  0             0   \n",
       "4  ...           0             0           0                  0             0   \n",
       "\n",
       "   fr_thiazole  fr_thiocyan  fr_thiophene  fr_unbrch_alkane  fr_urea  \n",
       "0            0            0             0                 0        0  \n",
       "1            0            0             0                 0        0  \n",
       "2            0            0             0                 0        0  \n",
       "3            0            0             0                 0        0  \n",
       "4            0            0             0                 1        0  \n",
       "\n",
       "[5 rows x 221 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "Location = r'C:\\Users\\wanih\\\\CXCR4\\\\Dataset_training_descriptors.csv'\n",
    "df = pd.read_csv(Location)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Activity\n",
       "1    381\n",
       "0    227\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Activity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, 4:]\n",
    "y = df[\"Activity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Dataset Spliting\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state= 2026) # different values of random seed were used [0, 42, 123, 1001, 2026]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "#Fit and Transform the data\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "with open(\"standard_scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = x_train.columns\n",
    "lst2 = x_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = pd.DataFrame(x_train_scaled,columns=lst)\n",
    "x_test_df = pd.DataFrame(x_test_scaled,columns=lst2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Selection using boruta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Initialize Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_jobs=-1,random_state= 0)\n",
    "\n",
    "#Step 2: Initialize Boruta\n",
    "boruta_selector = BorutaPy(rf,n_estimators='auto',random_state= 0)\n",
    "\n",
    "#Step 3: Fit Boruta on the data\n",
    "boruta_selector.fit(x_train_df.values,y_train.values)\n",
    "\n",
    "# Step 4: Get selected features\n",
    "selected_features = x_train_df.columns[boruta_selector.support_]\n",
    "#Convert the selected features to a DataFrame to save as Excel\n",
    "selected_features_df = pd.DataFrame(selected_features, columns=['Selected Features'])\n",
    "#Save the selected features to an Excel file\n",
    "selected_features_df.to_csv('cxcr4_selected_features.csv',index=False)\n",
    "selected_features_df\n",
    "\n",
    "x_train_selected = x_train_df[selected_features]\n",
    "x_test_selected = x_test_df[selected_features]\n",
    "\n",
    "#Step 5:Train Random Forest on selected features\n",
    "rf.fit(x_train_selected[selected_features],y_train)\n",
    "feature_importances = rf.feature_importances_\n",
    "#Create a DataFrame of selected features and their importances\n",
    "selected_df = pd.DataFrame({\n",
    "    'Selected Features': selected_features,\n",
    "    'Feature Importance': feature_importances\n",
    "}).sort_values(by='Feature Importance', ascending=False)\n",
    "#Round feature importances to two decimal places\n",
    "selected_df['Feature Importance'] = selected_df['Feature Importance'].round(3)\n",
    "#save the dataframe\n",
    "selected_df.to_csv('cxcr4_important_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Index to list (important for portability)\n",
    "selected_features_list = list(selected_features)\n",
    "\n",
    "with open(\"selected_features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(selected_features_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyper tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'criterion': 'gini', 'max_features': 15, 'min_samples_leaf': 5, 'splitter': 'best'}\n",
      "Best cross-validation score:  0.7798088410991637\n"
     ]
    }
   ],
   "source": [
    "model_dt = DecisionTreeClassifier(random_state= 0,max_depth=5)\n",
    "#tuning parameters\n",
    "param_grid = {\n",
    "    'splitter': ['best', 'random'],\n",
    "    'min_samples_leaf': [1,3,5,7],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    # 'max_depth':[1,3,5,7,9],\n",
    "    'max_features':[1,3,5,7,9,11,13,15,17]\n",
    "    }\n",
    "grid_search = GridSearchCV(model_dt,param_grid=param_grid,scoring='roc_auc',cv= 5,n_jobs=-1)\n",
    "\n",
    "#Fit the grid search to the training data\n",
    "grid_search.fit(x_train_selected,y_train)\n",
    "\n",
    "#best parameters found by the grid search\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'leaf_size': 1, 'metric': 'chebyshev', 'n_neighbors': 9}\n",
      "Best cross-validation score: 0.7837311450777456\n"
     ]
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(algorithm='auto')\n",
    "#tuning parameters\n",
    "param_grid = {\n",
    "    'leaf_size': list(range(1,10)),\n",
    "    'n_neighbors': list(range(1,10)),\n",
    "    'metric': ['minkowski', 'euclidean', 'manhattan', 'chebyshev'],\n",
    "   \n",
    "}\n",
    "#Deterministic cross-validation splitting\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "#grid search\n",
    "grid_search=GridSearchCV(model_knn,param_grid=param_grid,cv=cv,scoring='roc_auc',n_jobs=-1)\n",
    "\n",
    "#Fit the grid search to the training data\n",
    "grid_search.fit(x_train_selected,y_train)\n",
    "\n",
    "#best parameters found by the grid search\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best cross-validation score:  0.7786140979689367\n"
     ]
    }
   ],
   "source": [
    "model_svm = SVC(random_state= 0,class_weight='balanced')\n",
    "#tunning parameters\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1],\n",
    "    'gamma': [0.1, 0.01, 0.001, 0.0001],\n",
    "    'kernel': ['linear', 'rbf','sigmoid']\n",
    "}\n",
    "grid_search = GridSearchCV(model_svm,param_grid=param_grid,cv=5,scoring='roc_auc',n_jobs=-1)\n",
    "\n",
    "#Fit the grid search to the training data\n",
    "grid_search.fit(x_train_selected,y_train)\n",
    "\n",
    "#Print the best parameters found by the grid search\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'solver': 'liblinear', 'tol': 0.001}\n",
      "Best cross-validation score: 0.7724014336917564\n"
     ]
    }
   ],
   "source": [
    "model_lr=LogisticRegression(max_iter=40,random_state= 0)\n",
    "#tunning parameters\n",
    "param_grid = {\n",
    "    'C': [0.1, 0.01, 0.001, 1],\n",
    "    'solver': ['liblinear','saga'],\n",
    "    'tol': [0.1,0.01,0.001]\n",
    "}\n",
    "grid_search=GridSearchCV(model_lr,param_grid=param_grid,cv=5,scoring='roc_auc',n_jobs=-1)\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(x_train_selected,y_train)\n",
    "# Print the best parameters found by the grid search\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost decision tree (ABDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'algorithm': 'SAMME', 'learning_rate': 1, 'n_estimators': 50}\n",
      "Best cross-validation score:  0.7678614097968935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wanih\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize a base learner (DecisionTreeClassifier with max depth 1)\n",
    "base_learner = DecisionTreeClassifier(max_depth=1,random_state= 0)\n",
    "\n",
    "# Initialize AdaBoost with the base estimator (use 'estimator' instead of 'base_estimator')\n",
    "model_adbst = AdaBoostClassifier(estimator=base_learner,random_state= 0)\n",
    "#tuning parameters\n",
    "param_grid = {\n",
    "    'n_estimators': [10,15,20,25,30,35,40,45,50],\n",
    "    'algorithm': ['SAMME'],\n",
    "    'learning_rate': [0.001,0.01, 0.1,1]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(model_adbst,param_grid=param_grid,cv=5,scoring='roc_auc',n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(x_train_selected,y_train)\n",
    "\n",
    "# Print the best parameters found by the grid search\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'criterion': 'gini', 'max_features': 1, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 10}\n",
      "Best cross-validation score:  0.8311230585424132\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(max_depth=5,random_state= 0)\n",
    "#tunning parameters\n",
    "param_grid = {\n",
    "#     'max_depth': [3,5,7],\n",
    "    'n_estimators': list(range(10,30)),\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': list(range(1,14)),\n",
    "    'min_samples_split': list(range(2, 10)),\n",
    "    'min_samples_leaf': list(range(1, 10))\n",
    "}\n",
    "grid_search = GridSearchCV(model_rf,param_grid=param_grid,cv=5,scoring='roc_auc',n_jobs=-1)\n",
    "#Fit the grid search to the training data\n",
    "grid_search.fit(x_train_selected,y_train)\n",
    "#best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models and Performance matricss and Performance matrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "base_learner = DecisionTreeClassifier(max_depth=1,random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define models\n",
    "models = []\n",
    "models.append(('DT', DecisionTreeClassifier(random_state= 0,max_depth= 5,criterion='entropy', max_features= 7,min_samples_leaf=5,splitter='best')))\n",
    "models.append(('KNN',KNeighborsClassifier(leaf_size= 3, n_neighbors= 9,metric='manhattan',algorithm='auto')))\n",
    "models.append(('SVM',SVC(random_state=0,C=0.1,gamma= 0.1,kernel='rbf',class_weight='balanced')))\n",
    "models.append(('RF', RandomForestClassifier(max_depth=5,random_state=0,criterion='gini',n_estimators= 24,max_features= 2,min_samples_leaf=1,min_samples_split=5)))\n",
    "models.append(('LR', LogisticRegression(C=1, random_state= 0, solver='liblinear',max_iter=40,tol=0.1)))\n",
    "models.append(('ABDT',AdaBoostClassifier(estimator=base_learner,random_state=0,algorithm='SAMME',learning_rate= 1,n_estimators=50)))\n",
    "\n",
    "# Initialize result lists and names list\n",
    "result1_train = []  # For storing training ACCURACY results\n",
    "result2_train = []  # For storing training ROC_AUC results\n",
    "result3_train = []  # For storing training F1_SCORE results\n",
    "result4_train = []  # For storing training RECALL results\n",
    "result5_train = []  # For storing training SPECIFICITY results\n",
    "result6_train = []  # For storing training PRESCISION results\n",
    "result7_train = []  # For storing training MCC results\n",
    "\n",
    "result1_test = []   # For storing test ACCURACY results\n",
    "result2_test = []   # For storing test ROC_AUC results\n",
    "result3_test = []   # For storing test F1_SCORE results\n",
    "result4_test = []   # For storing test RECALL results\n",
    "result5_test = []   # For storing test SPECIFICITY results\n",
    "result6_test = []   # For storing test PRESCISION results\n",
    "result7_test = []   # For storing test MCC results\n",
    "\n",
    "names = []  #For storing model names\n",
    "\n",
    "# Loop through models and calculate metrics for both training and test sets\n",
    "for name, model in models:\n",
    "    # Fit the model on the training data\n",
    "    model.fit(x_train_selected, y_train)\n",
    "    \n",
    "    # Get predictions for the training and test sets\n",
    "    y_train_pred = model.predict(x_train_selected)\n",
    "    y_test_pred = model.predict(x_test_selected)\n",
    "    \n",
    "    # Calculate metrics for the training set\n",
    "    accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "    auc_roc_train = roc_auc_score(y_train, y_train_pred)\n",
    "    f1_train = f1_score(y_train, y_train_pred)  # F1-score for training set\n",
    "    recall_train = recall_score(y_train, y_train_pred)\n",
    "    precision_train = precision_score(y_train, y_train_pred)\n",
    "    mcc_train = matthews_corrcoef(y_train, y_train_pred)  # MCC for training set\n",
    "    # Calculate specificity for the training set\n",
    "    tn_train, fp_train, fn_train, tp_train = confusion_matrix(y_train, y_train_pred).ravel()\n",
    "    specificity_train = tn_train / (tn_train + fp_train)\n",
    "    \n",
    "    # Append the results to the training result lists\n",
    "    result1_train.append(round(accuracy_train * 100, 2))          # Accuracy as percentage\n",
    "    result2_train.append(round(auc_roc_train * 100, 2))           # AUC-ROC as percentage\n",
    "    result3_train.append(round(f1_train, 2))                      # F1-Score as percentage\n",
    "    result4_train.append(round(recall_train * 100, 2))            # Recall as percentage\n",
    "    result5_train.append(round(specificity_train * 100, 2))       # Specificity as percentage\n",
    "    result6_train.append(round(precision_train * 100, 2))         # Precision as percentage\n",
    "    result7_train.append(round(mcc_train, 2))                     # MCC as percentage\n",
    "\n",
    "    # Calculate metrics for the test set\n",
    "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "    auc_roc_test = roc_auc_score(y_test, y_test_pred)\n",
    "    f1_test = f1_score(y_test, y_test_pred)  # F1-score for test set\n",
    "    recall_test = recall_score(y_test, y_test_pred)\n",
    "    precision_test = precision_score(y_test, y_test_pred)\n",
    "    mcc_test = matthews_corrcoef(y_test, y_test_pred)  # MCC for test set\n",
    "\n",
    "    # Calculate specificity for the test set (True Negative Rate)\n",
    "    tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "    specificity_test = tn_test / (tn_test + fp_test)\n",
    "    \n",
    "    # Append the results to the test result lists\n",
    "    result1_test.append(round(accuracy_test * 100, 2))          # Accuracy as percentage\n",
    "    result2_test.append(round(auc_roc_test * 100, 2))           # AUC-ROC as percentage\n",
    "    result3_test.append(round(f1_test, 2))                      # F1-Score as percentage\n",
    "    result4_test.append(round(recall_test * 100, 2))            # Recall as percentage\n",
    "    result5_test.append(round(specificity_test * 100, 2))       # Specificity as percentage\n",
    "    result6_test.append(round(precision_test * 100, 2))         # Precision as percentage\n",
    "    result7_test.append(round(mcc_test, 2))                     # MCC as percentage\n",
    "    \n",
    "    # Append model name to the names list\n",
    "    names.append(name)\n",
    "\n",
    "# Create DataFrames for each metric for both training and test sets\n",
    "r1_train = pd.DataFrame(result1_train, columns=['Train_accuracy'], index=names)\n",
    "r2_train = pd.DataFrame(result2_train, columns=['Train_auc-roc'], index=names)\n",
    "r3_train = pd.DataFrame(result3_train, columns=['Train_f1-score'], index=names)\n",
    "r4_train = pd.DataFrame(result4_train, columns=['train_recall'], index=names)\n",
    "r5_train = pd.DataFrame(result5_train, columns=['Train_specificity'], index=names)\n",
    "r6_train = pd.DataFrame(result6_train, columns=['Train_precision'], index=names)\n",
    "r7_train = pd.DataFrame(result7_train, columns=['Train_MCC'], index=names)\n",
    "\n",
    "r1_test = pd.DataFrame(result1_test, columns=['Test_accuracy'], index=names)\n",
    "r2_test = pd.DataFrame(result2_test, columns=['Test_auc-roc'], index=names)\n",
    "r3_test = pd.DataFrame(result3_test, columns=['Test_f1-score'], index=names)\n",
    "r4_test = pd.DataFrame(result4_test, columns=['Test_recall'], index=names)\n",
    "r5_test = pd.DataFrame(result5_test, columns=['Test_specificity'], index=names)\n",
    "r6_test = pd.DataFrame(result6_test, columns=['Test_precision'], index=names)\n",
    "r7_test = pd.DataFrame(result7_test, columns=['Test_MCC'], index=names)\n",
    "# Concatenate the DataFrames for both training and test sets along axis 1\n",
    "trn_performance_matrics= pd.concat([r1_train,r2_train,r3_train,r4_train,r5_train,r6_train,r7_train], axis=1)\n",
    "tst_performance_matrics = pd.concat([r1_test, r2_test,r3_test,r4_test,r5_test, r6_test, r7_test], axis=1)\n",
    "# Display the final DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_accuracy</th>\n",
       "      <th>Train_auc-roc</th>\n",
       "      <th>Train_f1-score</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>Train_specificity</th>\n",
       "      <th>Train_precision</th>\n",
       "      <th>Train_MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>83.06</td>\n",
       "      <td>82.58</td>\n",
       "      <td>0.86</td>\n",
       "      <td>84.67</td>\n",
       "      <td>80.49</td>\n",
       "      <td>87.35</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>78.82</td>\n",
       "      <td>74.03</td>\n",
       "      <td>0.85</td>\n",
       "      <td>95.02</td>\n",
       "      <td>53.05</td>\n",
       "      <td>76.31</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>79.29</td>\n",
       "      <td>76.80</td>\n",
       "      <td>0.84</td>\n",
       "      <td>87.74</td>\n",
       "      <td>65.85</td>\n",
       "      <td>80.35</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>86.12</td>\n",
       "      <td>82.47</td>\n",
       "      <td>0.90</td>\n",
       "      <td>98.47</td>\n",
       "      <td>66.46</td>\n",
       "      <td>82.37</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>79.53</td>\n",
       "      <td>75.29</td>\n",
       "      <td>0.85</td>\n",
       "      <td>93.87</td>\n",
       "      <td>56.71</td>\n",
       "      <td>77.53</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABDT</th>\n",
       "      <td>82.35</td>\n",
       "      <td>78.83</td>\n",
       "      <td>0.87</td>\n",
       "      <td>94.25</td>\n",
       "      <td>63.41</td>\n",
       "      <td>80.39</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train_accuracy  Train_auc-roc  Train_f1-score  train_recall  \\\n",
       "DT             83.06          82.58            0.86         84.67   \n",
       "KNN            78.82          74.03            0.85         95.02   \n",
       "SVM            79.29          76.80            0.84         87.74   \n",
       "RF             86.12          82.47            0.90         98.47   \n",
       "LR             79.53          75.29            0.85         93.87   \n",
       "ABDT           82.35          78.83            0.87         94.25   \n",
       "\n",
       "      Train_specificity  Train_precision  Train_MCC  \n",
       "DT                80.49            87.35       0.65  \n",
       "KNN               53.05            76.31       0.55  \n",
       "SVM               65.85            80.35       0.56  \n",
       "RF                66.46            82.37       0.72  \n",
       "LR                56.71            77.53       0.56  \n",
       "ABDT              63.41            80.39       0.63  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_performance_matrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_accuracy</th>\n",
       "      <th>Test_auc-roc</th>\n",
       "      <th>Test_f1-score</th>\n",
       "      <th>Test_recall</th>\n",
       "      <th>Test_specificity</th>\n",
       "      <th>Test_precision</th>\n",
       "      <th>Test_MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>70.49</td>\n",
       "      <td>68.83</td>\n",
       "      <td>0.77</td>\n",
       "      <td>74.17</td>\n",
       "      <td>63.49</td>\n",
       "      <td>79.46</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>77.60</td>\n",
       "      <td>71.23</td>\n",
       "      <td>0.84</td>\n",
       "      <td>91.67</td>\n",
       "      <td>50.79</td>\n",
       "      <td>78.01</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>68.85</td>\n",
       "      <td>66.07</td>\n",
       "      <td>0.76</td>\n",
       "      <td>75.00</td>\n",
       "      <td>57.14</td>\n",
       "      <td>76.92</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>77.05</td>\n",
       "      <td>70.44</td>\n",
       "      <td>0.84</td>\n",
       "      <td>91.67</td>\n",
       "      <td>49.21</td>\n",
       "      <td>77.46</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>75.96</td>\n",
       "      <td>70.73</td>\n",
       "      <td>0.83</td>\n",
       "      <td>87.50</td>\n",
       "      <td>53.97</td>\n",
       "      <td>78.36</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABDT</th>\n",
       "      <td>74.86</td>\n",
       "      <td>69.90</td>\n",
       "      <td>0.82</td>\n",
       "      <td>85.83</td>\n",
       "      <td>53.97</td>\n",
       "      <td>78.03</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Test_accuracy  Test_auc-roc  Test_f1-score  Test_recall  \\\n",
       "DT            70.49         68.83           0.77        74.17   \n",
       "KNN           77.60         71.23           0.84        91.67   \n",
       "SVM           68.85         66.07           0.76        75.00   \n",
       "RF            77.05         70.44           0.84        91.67   \n",
       "LR            75.96         70.73           0.83        87.50   \n",
       "ABDT          74.86         69.90           0.82        85.83   \n",
       "\n",
       "      Test_specificity  Test_precision  Test_MCC  \n",
       "DT               63.49           79.46      0.37  \n",
       "KNN              50.79           78.01      0.48  \n",
       "SVM              57.14           76.92      0.32  \n",
       "RF               49.21           77.46      0.47  \n",
       "LR               53.97           78.36      0.44  \n",
       "ABDT             53.97           78.03      0.42  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_performance_matrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training of all model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT=DecisionTreeClassifier(random_state= 0,max_depth= 5,criterion='entropy', max_features= 7,min_samples_leaf=5,splitter='best')\n",
    "KNN=KNeighborsClassifier(leaf_size= 3, n_neighbors= 9,metric='manhattan',algorithm='auto')\n",
    "SVM=SVC(random_state=0,C=0.1,gamma= 0.1,kernel='rbf',class_weight='balanced')\n",
    "RF=RandomForestClassifier(max_depth=5,random_state=0,criterion='gini',n_estimators= 24,max_features= 2,min_samples_leaf=1,min_samples_split=5)\n",
    "LR=LogisticRegression(C=1, random_state= 0, solver='liblinear',max_iter=40,tol=0.1)\n",
    "ADBT=AdaBoostClassifier(estimator=base_learner,random_state=0,algorithm='SAMME',learning_rate= 1,n_estimators=50)\n",
    "\n",
    "mod_dt=DT.fit(x_train_selected,y_train)\n",
    "mod_knn=KNN.fit(x_train_selected,y_train)\n",
    "mod_svm=SVM.fit(x_train_selected,y_train)\n",
    "mod_rf=RF.fit(x_train_selected,y_train)\n",
    "mod_lr=LR.fit(x_train_selected,y_train)\n",
    "mod_adbt=ADBT.fit(x_train_selected,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models pickled successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "models = {\n",
    "    \"dt\": mod_dt,\n",
    "    \"knn\": mod_knn,\n",
    "    \"svm\": mod_svm,\n",
    "    \"rf\": mod_rf,\n",
    "    \"lr\": mod_lr,\n",
    "    \"adbt\": mod_adbt\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    with open(f\"{name}_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "print(\"All models pickled successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
